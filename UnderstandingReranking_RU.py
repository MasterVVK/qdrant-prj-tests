from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct
from sentence_transformers import SentenceTransformer, CrossEncoder
import pandas as pd

# Подключение к Qdrant
#client = QdrantClient(
#    url="<ADD-URL>",
#    api_key="<API-KEY>",
#)

client = QdrantClient(url="http://localhost:6333")
print(client.get_collections())

# Используем BGE-M3 для эмбеддингов и реранкинга
embedding_model = SentenceTransformer("BAAI/bge-large-en")  # BGE-M3 для эмбеддингов
rerank_model = CrossEncoder("BAAI/bge-reranker-large")  # BGE-M3 для реранкинга

embedding_model = SentenceTransformer("BAAI/bge-m3")  # BGE-M3 для эмбеддингов на русском
rerank_model = CrossEncoder("BAAI/bge-reranker-v2-m3")  # BGE-M3 для реранкинга

# Создание коллекции в Qdrant
if not client.collection_exists("basic-search-rerank_RU"):
    client.create_collection(
	collection_name="basic-search-rerank_RU",
	vectors_config=VectorParams(size=1024, distance=Distance.DOT),
    )

# Пример данных


query = "Какова цель масштабирования признаков в машинном обучении?"

documents = [
    "В машинном обучении масштабирование признаков – это процесс нормализации диапазона независимых переменных или признаков. Его цель – обеспечить равномерный вклад всех признаков в модель, особенно в алгоритмах, таких как SVM или k-ближайших соседей, где важны вычисления расстояний.",

    "Масштабирование признаков часто используется на этапе предварительной обработки данных, чтобы привести признаки к одному масштабу. Это особенно важно для алгоритмов, основанных на градиентном спуске, так как признаки с большими значениями могут непропорционально влиять на функцию стоимости.",

    "В науке о данных процесс извлечения признаков включает преобразование необработанных данных в набор инженерных признаков, используемых в моделях прогнозирования. Масштабирование признаков связано с этим процессом, но его основная цель – корректировка значений этих признаков.",

    "Алгоритмы обучения без учителя, такие как методы кластеризации, могут выигрывать от масштабирования признаков, поскольку оно предотвращает доминирование признаков с большими числовыми диапазонами.",

    "Одна из популярных техник предварительной обработки данных – отбор признаков. В отличие от масштабирования, он направлен на уменьшение количества входных переменных модели для предотвращения переобучения.",

    "Анализ главных компонент (PCA) – это метод уменьшения размерности, который работает лучше при масштабированных данных, поскольку он основан на дисперсии, которая может быть искажена признаками с разными масштабами.",

    "Мин-макс нормализация – это популярный метод масштабирования, который обычно приводит значения признаков к фиксированному диапазону [0, 1]. Этот метод особенно полезен, когда данные не имеют нормального распределения.",

    "Стандартизация (z-score нормализация) – еще один метод, который преобразует признаки таким образом, чтобы их среднее значение было 0, а стандартное отклонение – 1. Этот метод эффективен, если данные имеют нормальное распределение.",

    "Масштабирование признаков критически важно при использовании алгоритмов, основанных на расстояниях, например, в k-средних кластеризации, поскольку немасштабированные признаки могут приводить к некорректным результатам.",

    "Градиентный спуск работает эффективнее при масштабировании, так как различия в масштабе признаков могут замедлить сходимость алгоритма.",

    "В глубоком обучении масштабирование признаков помогает стабилизировать процесс обучения, обеспечивая быструю и стабильную сходимость моделей.",

    "Робастное масштабирование – еще один метод, использующий медиану и межквартильный размах для масштабирования признаков, что делает его менее чувствительным к выбросам.",

    "При работе с временными рядами масштабирование помогает стандартизировать входные данные и улучшить производительность модели на разных временных периодах.",

    "Нормализация часто используется в обработке изображений для приведения значений пикселей в определенный диапазон, что улучшает работу моделей компьютерного зрения.",

    "Масштабирование особенно важно, когда признаки имеют разные единицы измерения, например, рост в сантиметрах и вес в килограммах.",

    "В системах рекомендаций масштабирование признаков, таких как рейтинги пользователей, может улучшить способность модели находить похожих пользователей или объекты.",

    "Методы уменьшения размерности, такие как t-SNE и UMAP, требуют масштабирования признаков для корректной визуализации многомерных данных в меньших измерениях.",

    "Методы обнаружения выбросов могут выигрывать от масштабирования, так как выбросы могут быть усилены или ослаблены признаками с разными масштабами.",

    "Предварительная обработка данных, включая масштабирование, может существенно повлиять на производительность моделей машинного обучения, поэтому это важный этап подготовки данных.",

    "В ансамблевых методах, таких как случайный лес, масштабирование не является строго обязательным, но может улучшить интерпретируемость модели и сравнение значимости признаков.",

    "Масштабирование должно применяться одинаково к обучающим и тестовым данным, чтобы избежать утечки данных и обеспечить корректную оценку модели.",

    "В обработке естественного языка (NLP) масштабирование может быть полезно при работе с числовыми признаками из текстов, например, частотой встречаемости слов.",

    "Логарифмическое преобразование можно применять к асимметричным данным для стабилизации дисперсии и улучшения процесса масштабирования.",

    "В методах увеличения данных (data augmentation) масштабирование может использоваться для обеспечения консистентности обучающего набора, особенно в задачах компьютерного зрения."
]


# Генерация эмбеддингов с помощью BGE-M3
doc_embeddings = [embedding_model.encode(doc).tolist() for doc in documents]

# Запись эмбеддингов в Qdrant
points = [
    PointStruct(
        id=idx,
        vector=embedding,
        payload={"document": doc}
    )
    for idx, (embedding, doc) in enumerate(zip(doc_embeddings, documents))
]

operation_info = client.upsert(
    collection_name="basic-search-rerank_RU",
    points=points
)

# Преобразование запроса в эмбеддинг
query_embedding = embedding_model.encode(query).tolist()

# Поиск векторных ближайших соседей
search_result = client.query_points(
    collection_name="basic-search-rerank_RU", query=query_embedding, limit=10
).points

document_list = [point.payload['document'] for point in search_result]
document_ids = [point.id for point in search_result]
document_scores = [point.score for point in search_result]

# Вывод результатов поиска
search_results_df = pd.DataFrame({
    "ID": document_ids,
    "Document": [doc[:80] + "..." for doc in document_list],
    "Score": document_scores
})
print(search_results_df)

document_list = [point.payload['document'] for point in search_result]

# Реранкинг результатов с помощью BGE-M3
#scores = rerank_model.predict([(query, doc) for doc in document_list])
#reranked_results = [x for _, x in sorted(zip(scores, document_list), reverse=True)]

# Вывод результатов
#for i, doc in enumerate(reranked_results[:5]):
#    print(f"{i+1}. {doc}")
# Реранкинг результатов с помощью BGE-M3
scores = rerank_model.predict([(query, doc) for doc in document_list])
reranked_data = sorted(zip(document_ids, document_list, scores), key=lambda x: x[2], reverse=True)

# Вывод результатов реранкинга
reranked_results_df = pd.DataFrame({
    "ID": [doc_id for doc_id, _, _ in reranked_data],
    "Document": [doc[:80] + "..." for _, doc, _ in reranked_data],
    "Score": [score for _, _, score in reranked_data]
})
print(reranked_results_df)

